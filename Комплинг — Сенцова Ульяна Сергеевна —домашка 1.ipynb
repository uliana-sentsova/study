{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Языковое моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем работать с корпусом шекспировских текстов. Для того, чтобы его скачать, введите:\n",
    "```python\n",
    "!wget http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
    "```\n",
    "\n",
    "**Проделайте следующие упражнения:**\n",
    "1. Разбейте текст на слова.\n",
    "2. Приведите все к нижнему регистру.\n",
    "3. Посчитайте частоты всех слов.\n",
    "4. Замените слова с частотой встречаемости ниже 2 на UNK.\n",
    "5. Создайте словарь, где по ключу _i_ будет лежать словарь с частотами _n_-грамм длины _i_.\n",
    "6. Напишите функцию для оценки вероятностей предложений при помощи данного словаря с использованием сглаживания Лапласа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Вспомогательаня функция для замены нечастотных слов тэгом UNK\n",
    "def replace_(word, frequency_dict):\n",
    "    if frequency_dict[word] < 2:\n",
    "        return \"UNK\"\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "# Функция для удаления лишних символов в слове(знаки препинания)\n",
    "def strip_(word):\n",
    "    word = word.strip()\n",
    "    result = \"\"\n",
    "    for symbol in word:\n",
    "        if symbol not in \".,!@#$%^&*()_+:\\\"'|/\":\n",
    "            result += symbol\n",
    "    return result.lower()\n",
    "\n",
    "with open(\"shakespeare_input.txt\", 'r') as fin:\n",
    "    frequency_dict = defaultdict(int)\n",
    "    fin = fin.read(10000)\n",
    "    text = [strip_(word.lower()) for word in fin.split()]\n",
    "    for word in text:\n",
    "        frequency_dict[word] += 1\n",
    "    text = [replace_(word, frequency_dict) for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Вспомогательная функция для создания словаря n-граммов длины n из заданного текста:\n",
    "def create_dict(n, text):\n",
    "    d = defaultdict(int)\n",
    "    current_index = 0\n",
    "    for i in range(0, len(text) - n + 1):\n",
    "        bigram = ''\n",
    "        for j in range(0, n):\n",
    "            bigram += \" \" + text[i + j]\n",
    "        bigram = bigram.strip()\n",
    "        d[bigram] += 1.0\n",
    "    total = sum(d.values())\n",
    "    total += len(list(set(d.keys())))\n",
    "    for key in d:\n",
    "        d[key] = (float(d[key]) / total) + 1.0\n",
    "    d[\"UNK\"] = 1.0\n",
    "    return d\n",
    "\n",
    "# Вспомогательная функция для создания словаря словарей\n",
    "# (ключ словаря - целое число, означающее длину n-грамма,\n",
    "# значение – словарь таких n-граммов):\n",
    "def create_meta_dict(n, text):\n",
    "    dictionary = defaultdict(dict)\n",
    "    for i in range(1, n + 1):\n",
    "        dictionary[i] = create_dict(i, text)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def tokenize_text(text):\n",
    "    text = re.split(\"\\.|\\n|\\?|!\", text)\n",
    "    return [strip_(t) for t in text if t]\n",
    "sentences = tokenize_text(fin)\n",
    "\n",
    "# Чтобы не создавать слишком много словарей n-граммов, ограничим n длиной самого длинного предложения:\n",
    "max_length = len(max(sentences, key=lambda x: len(x)).split())\n",
    "print(max_length)\n",
    "dictionary = create_meta_dict(max_length, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Функция для оценки вероятности предложения по биграммной модели:\n",
    "\n",
    "def joint(tokens, dictionary):\n",
    "    x = dictionary[len(tokens.split())][tokens]\n",
    "    if x != 0.0:\n",
    "        return x\n",
    "    else:\n",
    "        return 1.0\n",
    "    \n",
    "\n",
    "def cond_prob(tokens, dictionary):\n",
    "    joint_prob = joint(tokens, dictionary)\n",
    "    tokens = tokens.split(\" \")\n",
    "    p = dictionary[1][tokens[0]]\n",
    "    return joint_prob / p\n",
    "\n",
    "\n",
    "def sentence_probability(sentence, dictionary):\n",
    "    sentence = sentence.split()\n",
    "    sentence = [replace_(word, frequency_dict) for word in sentence]\n",
    "    span = sentence[0]\n",
    "    prob = dictionary[1][span]\n",
    "    for i in range(1, len(sentence)):\n",
    "        span += \" \" + sentence[i]\n",
    "        prob *= cond_prob(span, dictionary)\n",
    "        s = []\n",
    "        span = span.split(\" \")\n",
    "        s.append(span[-2])\n",
    "        s.append(span[-1])\n",
    "        span = \" \".join(s)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация случайных текстов (Д/З)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы сгенерировать случайный текст нужно запастись двумя вещами:\n",
    "\n",
    "1. Тренировочный корпус.\n",
    "2. Языковая модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С первым все совсем легко. Запустите строчку, указанную ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут уже поинтересней. Следуя комментариям напишите класс, реализующий простейшую **побуквенную** языковую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "class LanguageModel:\n",
    "    def __init__(self, data, order=4):\n",
    "        self.order = order\n",
    "        self.ngrams = defaultdict(Counter)\n",
    "        pad = '~' * order\n",
    "        data = pad + data\n",
    "        \n",
    "        # For each ngram in data count all characters following this ngram.\n",
    "        # For instance for oder = 2 and data = 'abcbcb' self.ngrams should be the following:\n",
    "        # self.ngrams['~~']['a'] == 1\n",
    "        # self.ngrams['~a']['b'] == 1\n",
    "        # self.ngrams['ab']['c'] == 1\n",
    "        # self.ngrams['bc']['c'] == 2\n",
    "        # self.ngrams['cb']['c'] == 1\n",
    "                \n",
    "        for current_index in range(0, len(data) - order):\n",
    "            ngram = ''\n",
    "            for i in range(0, order):\n",
    "                ngram += data[current_index + i]\n",
    "            \n",
    "            self.ngrams[ngram][data[current_index + order]] += 1.\n",
    "\n",
    "        self.lm = {history: self.normalize(chars) for history, chars in self.ngrams.items()}\n",
    "    \n",
    "    def normalize(self, counter):\n",
    "        total = sum([counter[c] for c in counter])\n",
    "        return [(c, counter[c]/total) for c in counter]\n",
    "    \n",
    "    def __getitem__(self, history):\n",
    "        return self.lm[history]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что-ж, пришло время обучить языковую модельку и проверить результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('shakespeare_input.txt', 'r') as fin:\n",
    "    lm = LanguageModel(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 0.0068143100511073255),\n",
       " (' ', 0.013628620102214651),\n",
       " (\"'\", 0.017035775127768313),\n",
       " (',', 0.027257240204429302),\n",
       " ('.', 0.0068143100511073255),\n",
       " ('r', 0.059625212947189095),\n",
       " ('u', 0.03747870528109029),\n",
       " ('w', 0.817717206132879),\n",
       " ('n', 0.0017035775127768314),\n",
       " (':', 0.005110732538330494),\n",
       " ('?', 0.0068143100511073255)]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['ello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 1.0)]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['Firs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь напишем функцию для генерации случайных текстов!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def generate_letter(lm, history):\n",
    "    next_letter = max(lm[history], key=lambda x:x[1])\n",
    "    return next_letter[0]\n",
    "        \n",
    "def generate_text(lm, n_letters=1000):\n",
    "    history = '~' * lm.order\n",
    "    out = []\n",
    "    for i in range(0, n_letters):\n",
    "        next_letter = generate_letter(lm, history)\n",
    "        out.append(next_letter)\n",
    "        history += next_letter\n",
    "        history = history[-lm.order:]\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Senator:\n",
      "The shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the shall the s\n"
     ]
    }
   ],
   "source": [
    "with open('shakespeare_input.txt', 'r') as fin:\n",
    "    lm = LanguageModel(fin.read())\n",
    "\n",
    "print(generate_text(lm, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "We have seen the charge thee, and the son of my love to her sin and his company.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "I know not what they shall be so bold to say so in this contract of eternal spirit,\n",
      "And therefore the wind and set forth the same dish? for, in choosing me a cup of sack with him that hath a hand that the streets,\n",
      "And for the which he hath been a man of the world and a coward the Third, he bid you come to the sea was called the dead bodies shall be so bold to say so in this contract of eternal spirit,\n",
      "And therefore the wind and set forth the same dish? for, in choosing me a cup of sack with him that hath a hand that the streets,\n",
      "And for the which he hath been a man of the world and a coward the Third, he bid you come to the sea was called the dead bodies shall be so bold to say so in this contract of eternal spirit,\n",
      "And therefore the wind and set forth the same dish? for, in choosing me a cup of sack with him that hath a hand that the streets,\n",
      "And for the which he hath been a man of the world and a coward the Third, he bid you come to the sea was called the dead bodies shall be so bold to say so in this contract of eternal spirit,\n",
      "And therefore the wind and set forth the same dish? for, in choosing me a cup of sack with him that hath a hand that the streets,\n",
      "And for the which he hath been a man of the world and a coward the Third, he bid you come to the sea was called the dead bodies shall be so bold to say so in this contract of eternal spirit,\n",
      "And therefore the wind and set forth the same dish? for, in choosing me a cup of sack with him that hath a hand that the streets,\n",
      "And for the which he hath been a man of the world and a coward the Third, he bid you come to the sea was called the dead bodies shall be so bold to say so in this contract of eternal spirit,\n",
      "And therefore the wind and set forth the same dish? for, in choosing me a cup of sack with him that hath a hand that the streets,\n",
      "And for the which he hath been a man of the world and a coward the T\n"
     ]
    }
   ],
   "source": [
    "with open('shakespeare_input.txt', 'r') as fin:\n",
    "    lm = LanguageModel(fin.read(), 8)\n",
    "    \n",
    "print(generate_text(lm, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Bring him with triumph home unto his house.\n",
      "\n",
      "Second Citizen:\n",
      "What he cannot help in his nature, you account a\n",
      "vice in him. You must in no way say he is covetous.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians of you. For your wants,\n",
      "Your suffering in this dearth, you may as well\n",
      "Strike at the heaven with your ships:\n",
      "They are in readiness.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "And take my heart with extreme laughter:\n",
      "I pry'd me through the hole of this vile wall!\n",
      "\n",
      "Thisbe:\n",
      "I kiss the wall's hole, not your lips at all.\n",
      "\n",
      "Pyramus:\n",
      "Wilt thou at Ninny's tomb meet me straightway?\n",
      "\n",
      "Thisbe:\n",
      "'Tide life, 'tide death, I come without delay.\n",
      "\n",
      "Wall:\n",
      "Thus have I, Wall, my part discharged so;\n",
      "And, being done, thus Wall away doth go.\n",
      "\n",
      "THESEUS:\n",
      "Now is the mural down between the two moist elements,\n",
      "Like Perseus' horse: where's then the saucy boat\n",
      "Whose weak untimber'd sides but even now\n",
      "Co-rivall'd greatness? Either to harbour fled,\n",
      "Or made a toast for Neptune. Even so\n",
      "Doth valour's show and valour's worth divide\n",
      "In storms of fortune; for in her ray and brightness\n",
      "The herd hath more annoyance by the breeze\n",
      "Than by the tiger; but when the splitting wind\n",
      "Makes flexible the knees of knotted oaks,\n",
      "And flies fled under shade, why, then the thing of courage\n",
      "As roused with rage with rage doth sympathize,\n",
      "And with an accent tuned in selfsame key\n",
      "Retorts to chiding fortune.\n",
      "\n",
      "ULYSSES:\n",
      "Agamemnon,\n",
      "Thou great commanders,\n",
      "Sleeping neglection doth betray to loss\n",
      "The conquest of our scarce cold conqueror,\n",
      "That ever living man of memory,\n",
      "Henry the Fifth hales them\n",
      "to an hundred mischiefs, and makes them hungry,\n",
      "The more she gives them speech. Where do you live?\n",
      "\n",
      "MARINA:\n",
      "Where I am but a stranger: from the deck\n",
      "You may discern the place.\n",
      "\n",
      "PERICLES:\n",
      "Some other is more fit.\n",
      "\n",
      "First Knight:\n",
      "Contend not, sir; for we are gentlemen\n",
      "That every day under his household roof\n",
      "Did keep ten thousand men;\n",
      "An older and a better soldier than he you wot on.\n",
      "\n",
      "Second Servingman:\n",
      "And I shall.\n",
      "\n",
      "Third Servingman:\n",
      "Wha\n"
     ]
    }
   ],
   "source": [
    "with open('shakespeare_input.txt', 'r') as fin:\n",
    "    lm = LanguageModel(fin.read(), 16)\n",
    "    \n",
    "print(generate_text(lm, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
